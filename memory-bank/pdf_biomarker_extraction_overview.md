# PDF Biomarker Extraction: End-to-End Overview

This document summarizes the full process for extracting biomarkers from uploaded PDF lab reports in the Vein Diagram system. It references key files, functions, controls, and limitations, and is intended as a high-level technical overview for developers and maintainers.

---

## 1. PDF Upload & Initial Trigger
- **Frontend**: User uploads a PDF via the UI (handled by React, `pdfService.ts`).
- **Backend Endpoint**: `POST /api/pdfs/upload` (see `api_documentation.md`)
  - Saves the file, creates a `PDF` record (status: `pending`).
  - Triggers background processing via `process_pdf_background` (`app/services/pdf_service.py`).

## 2. Text Extraction from PDF
- **Function**: `pdf_service.extract_text_from_pdf`
- **Libraries**: `PyMuPDF` (fitz) for direct text extraction.
  - If text extraction fails, falls back to OCR:
    - `pdf2image` (convert up to 5 pages to images)
    - `pytesseract` (OCR, multiple PSM modes)
- **Output**: Dict mapping page numbers to extracted text.
- **Controls**: Logs and debug info saved for traceability.

## 3. Content Optimization & Token Reduction
- **Function**: `content_optimization.compress_text_content`
- **Purpose**: Aggressive content compression to reduce Claude API token usage
- **Techniques**:
  - Removes administrative data (contact info, CIN numbers, fax numbers)
  - Eliminates boilerplate text and method descriptions
  - Compresses repeated headers and formatting
  - Standardizes number formats
- **Results**: Achieves 99%+ token reduction while preserving biomarker data
- **Integration**: Applied before all Claude API calls

## 4. Metadata Extraction (LLM/Claude)
- **Function**: `metadata_parser.extract_metadata_with_claude`
- **Input**: Compressed text from first few pages.
- **LLM**: Claude (`claude-3-5-sonnet-20241022`) - Updated to latest non-deprecated model
- **Prompt**: Requests only specific metadata fields in strict JSON.
- **Controls**:
  - Timeout (45s)
  - JSON repair logic
  - Only updates specific fields in the `PDF` record
- **Limitations**: If Claude fails/times out, metadata may be incomplete.

## 5. Page Filtering (Heuristic Guardrail)
- **Function**: `pdf_service.filter_relevant_pages`
- **Logic**:
  - Loads biomarker names/aliases from `biomarker_aliases.json`
  - Scores each page for relevance (biomarker mentions, units, table-like structures)
  - Only pages with score â‰¥ 1 are processed for biomarkers
- **Purpose**: Reduces noise, controls cost/latency, avoids irrelevant LLM calls.

## 6. Enhanced Biomarker Extraction (LLM/Claude)
- **Function**: `pdf_service.process_pages_sequentially`
- **For Each Relevant Page**:
  - Calls `biomarker_parser.extract_biomarkers_with_claude`
    - **Model**: `claude-3-5-sonnet-20241022` (Updated from deprecated model)
    - **Enhanced Prompt**: Strict biomarker definition with clear valid/invalid examples
    - **Validation Rules**: Explicit filtering of contact info, administrative data, qualitative results
    - **Timeout**: 10 min per page
    - **JSON Repair**: Extensive logic for malformed/truncated JSON with specific fixes for common errors
    - **Enhanced Fallback**: Improved regex-based parser with comprehensive invalid name filtering
- **Aggregation**: Combines results, de-duplicates by standardized biomarker name.

## 7. Enhanced Biomarker Validation & Filtering
- **Function**: `biomarker_parser._process_biomarker` and fallback parser
- **New Filtering Capabilities**:
  - **Administrative Data**: Filters out fax numbers, CIN codes, email addresses, phone numbers
  - **Geographic Info**: Removes city names, addresses, postal codes
  - **Document Structure**: Excludes headers, footers, page numbers, method descriptions
  - **Qualitative Results**: Filters out "Normal", "Abnormal", "High", "Low" without measurements
  - **Contact Information**: Removes lab contact details, registration numbers
- **Pattern Recognition**: Advanced regex patterns to identify and exclude non-biomarker text
- **Validation**: Enhanced checks for proper biomarker structure (name + numerical value + unit)

## 8. Biomarker Standardization & Validation
- **Function**: `biomarker_parser._process_biomarker`
- **Steps**:
  - Converts values to floats
  - Standardizes units
  - Parses reference ranges
  - Enhanced categorization (added Immunology category for IgE, antibodies)
  - Checks for abnormal values
- **Purpose**: Ensures consistency and reliability in downstream analysis.

## 9. Database Storage
- **Entities**: `PDF`, `Biomarker`, `Profile` (see `database_schema.md`)
- **Action**: Stores each processed biomarker, linking to PDF and user profile.

## 10. Status Update & Confidence Scoring
- **Final Step**: Updates PDF record to `processed` or `error`.
- **Confidence**: Stores average confidence score from Claude for extracted biomarkers.

---

## Controls, Guardrails, and Limitations

### Enhanced Controls & Guardrails
- **Content Optimization**: Aggressive token reduction (99%+) while preserving biomarker data
- **Enhanced Prompts**: Strict biomarker definitions with clear valid/invalid examples
- **Advanced Filtering**: Comprehensive invalid name detection (100+ patterns)
- **Page Filtering**: Only relevant pages sent to LLM
- **Timeouts**: Strict timeouts for LLM calls (45s metadata, 10min/page biomarkers)
- **Enhanced Fallbacks**: Improved regex-based extraction with better filtering
- **Advanced JSON Repair**: Handles common Claude API response errors and truncation
- **Comprehensive Logging**: Debug logs with emojis and detailed context for easier troubleshooting
- **Standardization**: All biomarker data normalized for name, unit, and range
- **Error Handling**: Status set to `error` and error logged if any step fails

### Resolved Issues
- **Token Optimization**: Fixed token increase issue (was 106% increase, now 99% reduction)
- **Invalid Extractions**: Eliminated extraction of contact info, administrative data, qualitative results
- **Model Updates**: Updated to latest non-deprecated Claude models
- **Enhanced Categorization**: Better biomarker classification including Immunology category

### Remaining Limitations
- **LLM Dependency**: Extraction accuracy depends on Claude's performance and prompt quality
- **OCR Quality**: Poor scans or complex layouts can reduce extraction accuracy
- **Heuristic Filtering**: May miss relevant pages or include irrelevant ones
- **Fallback Parser**: Regex-based extraction is less robust than LLM but significantly improved
- **Ambiguity**: Some data in PDFs may be inherently ambiguous
- **Rate Limits/Cost**: Sequential LLM calls can be slow/costly for large PDFs

---

## Summary Table: Key Files & Functions

| Step                        | File/Module                        | Key Function(s) / Endpoint                |
|-----------------------------|------------------------------------|-------------------------------------------|
| PDF Upload                  | `pdfService.ts` (frontend), `pdf_routes.py` (backend) | `/api/pdfs/upload`                        |
| Text Extraction             | `pdf_service.py`                   | `extract_text_from_pdf`                   |
| Content Optimization        | `content_optimization.py`         | `compress_text_content`                   |
| Metadata Extraction (LLM)   | `metadata_parser.py`               | `extract_metadata_with_claude`            |
| Page Filtering              | `pdf_service.py`                   | `filter_relevant_pages`                   |
| Biomarker Extraction (LLM)  | `biomarker_parser.py`              | `extract_biomarkers_with_claude`, `parse_biomarkers_from_text` |
| Standardization             | `biomarker_parser.py`              | `_process_biomarker`                      |
| Database Storage            | `pdf_service.py`, `biomarker_model.py` | ORM logic                                 |
| Status/Confidence Update    | `pdf_service.py`                   | Status update logic                       |

---

## Recent Critical Improvements (May 2025)

### Token Optimization Breakthrough
- **Problem**: Content optimization was increasing tokens by 106% instead of reducing them
- **Solution**: Implemented aggressive compression techniques removing administrative data, contact info, and boilerplate text
- **Result**: Achieved 99%+ token reduction while preserving biomarker information

### Enhanced Biomarker Filtering
- **Problem**: System was extracting invalid data like "Fax", "CIN numbers", "Normal", contact information
- **Solution**: Comprehensive filtering system with 100+ invalid patterns covering administrative data, geographic info, qualitative results
- **Result**: Eliminated extraction of non-biomarker text

### Claude Model Updates
- **Problem**: Using deprecated Claude models (`claude-3-sonnet-20240229`)
- **Solution**: Updated to latest models (`claude-3-5-sonnet-20241022`)
- **Result**: Improved extraction accuracy and future-proofed API calls

### Enhanced Prompt Engineering
- **Problem**: Prompts were not specific enough about what constitutes valid biomarkers
- **Solution**: Detailed prompts with explicit valid/invalid examples and strict validation rules
- **Result**: More accurate biomarker identification and reduced false positives

---

## References in @memory-bank
- `pdf_processing_details.md`: Full pipeline, controls, and limitations
- `claude_integration.md`: LLM prompt strategies, error handling, and fallback logic
- `database_schema.md`: Data model and relationships
- `.clinerules`: Step-by-step and known challenges
- `progress.md`, `activeContext.md`: Recent improvements, known issues, and ongoing work

---

**This document is intended as a living reference. Please update as the pipeline or controls evolve.** 